[role="xpack"]
[[ml-dfa-phases]]
=== How a {dfanalytics-job} works

A {dfanalytics-job} is essentially a persistent {es} task. During its life 
cycle, it goes through four main phases:

* reindexing,
* loading data,
* analyzing,
* writing results.

Let's take a look at the phases one-by-one.


[discrete]
==== Reindexing

During the reindexing phase the documents from the source index or indices are 
copied to the destination index. If you want to define settings or mappings, 
create the index before you start the job. Otherwise, the job creates it using 
default settings.

Once the destination index is built, the {dfanalytics-job} task calls the {es} 
{ref}/docs-reindex.html[Reindex API] to launch the reindexing task.


[discrete]
==== Loading data

After the reindexing is finished, the job fetches the needed data from the 
destination index. It converts the data into the format that the analysis 
process expects, then sends it to the analysis process.


[discrete]
==== Analyzing

When all the required data is loaded, the analyzing phase begins. The exact 
process always depends on the type of {dfanalytics} – for example, 
{classification} or {oldetection} – that is executed, you can find the 
description of these processes below ordered by analysis type. The analyzing 
phase is not reported in the `phase` property of the 
{ref}/get-dfanalytics-stats.html[Get {dfanalytics-jobs} statistics API], the 
specific sub-phases are reported instead.
In this phase, the job generates a {ml} model for analyzing the dataset.


[discrete]
===== {oldetection-cap}

{oldetection-cap} jobs have a single analysis phase called `computing_outliers`, in which they identify outliers in the data. 
`computing_outliers`. This is the phase when the {oldetection} analysis 
identifies outliers in the loaded data.


[discrete]
===== {regression-cap} and {classanalysis}

{regression-cap} and {classification} jobs have four analysis phases:
are four of them:

. `feature_selection`: Identifies which fields are significant for the analysis 
  field set to define which fields are significant for the analysis.
* `coarse_parameter_search`: This is the first part of 
  <<hyperparameters,hyperparameter optimization>> in which the process finds 
  suitable values for the hyperparameters that are required to run the analysis. 
* `fine_tuning_parameters`: After the values of hyperparameters are narrowed 
  down to a certain range in the `coarse_parameter_search` phase, the parameters 
  are further refined to an exact value in this second part of hyperparameter 
  optimization.
* `final_training`: This is the phase where the {ml} model training takes place.


[discrete]
==== Writing results

After the loaded data is analyzed, the analysis process sends back the results. 
Only the additional fields that the analysis calculated are written back, the 
ones that have been loaded in the loading data phase are not. The 
{dfanalytics-job} matches the results with the data rows in the destination 
index, merges them, and indexes them back to the destination index. When the 
process is complete, the task is marked as completed and the {dfanalytics-job} 
stops. Your data is ready to be evaluated.


Check the <<ml-dfa-concepts>> section if you'd like to know more about the 
various {dfanalytics} types.

Check the <<ml-dfanalytics-evaluate>> section if you are interested in the 
evaluation of the {dfanalytics} results.
