[role="xpack"]
[testenv="platinum"]
[[ml-dfa-finding-outliers]]
= Finding outliers

:keywords: {ml-init}, {stack}, {dfanalytics}, {oldetection}
:description: An introduction to {ml} {oldetection}, which enables you to  \
find unusual data points in a data set compared to the normal data points.

This page contains a conceptual overview of {oldetection} in the {stack} and a 
simple <<ecommerce-outliers,example>> of how to use it.


[discrete]
[[dfa-outlier-detection]]
== {oldetection-cap}

{oldetection-cap} is an analysis for identifying data points (outliers) whose 
feature values are different from those of the normal data points in a 
particular data set. Outliers may denote errors or unusual behavior. 
{oldetection-cap}, for example, can be used to detect malicious software on a 
machine, unusual user behavior on a network, or any unusual entity in a given 
population. As {oldetection} algorithms operate on the assumption that the 
outliers make up a small proportion of the overall data population. 

The {ml-features} provide unsupervised {oldetection}, which means there is no 
need to provide a training data set. Unsupervised {oldetection} uses various 
machine learning techniques to find which data points are unusual compared to 
the majority of the data points.

You can create {oldetection} {dfanalytics-jobs} in {kib} or by using the
{ref}/put-dfanalytics.html[create {dfanalytics-jobs} API].

[discrete]
[[dfa-outlier-algorithms]]
=== {oldetection-cap} algorithms

//tag::outlier-detection-algorithms[]
In the {stack}, we use an ensemble of four different distance and density based 
{oldetection} methods:

* distance of K^th^ nearest neighbor
* distance of K-nearest neighbors
* local outlier factor (`lof`)
* local distance-based outlier factor (`ldof`).
//end::outlier-detection-algorithms[]

By default, you don't need to select the methods or 
provide any parameters, but you can override the default behavior if you like. 
The basic assumption of the **distance based methods** is that normal data 
points – in other words, points that are not outliers – have a lot of neighbors 
nearby, because we expect that in a population the majority of the data points 
have similar feature values, while the minority of the data points – the 
outliers – have different feature values and will, therefore, be far away from 
the normal points.

//FIGURE ON DISTANCE BASED METHOD

The distance of K^th^ nearest neighbor method (`distance_kth_nn`) computes the 
distance of the data point to its K^th^ nearest neighbor where K is a small 
number and usually independent of the total number of data points. The higher 
this distance the more the data point is an outlier.

The distance of K-nearest neighbors method (`distance_knn`) calculates the 
average distance of the data points to their nearest neighbors. Points with the 
largest average distance will be the most outlying.

While the results of the distance based methods are easy to interpret, their 
drawback is that they don't take into account the density variations of a 
data set. This is the point where **density based methods** come into the 
picture, they are used for mitigating this problem. These methods take into 
account not only the distance of the points to their K nearest neighbors but 
also the distance of these neighbors to their neighbors.

//[role="screenshot"]
//image::ml/images/ml-densitybm.jpg["Density based method – By Chire - Own work, Public Domain, https://commons.wikimedia.org/w/index.php?curid=10423954"]

Based on this approach, a metric is computed called local outlier factor 
(`lof`) for each data point. The higher the local outlier factor, the more 
outlying is the data point.

The other density based method that {oldetection} uses is the local 
distance-based outlier factor (`ldof`). Ldof is a ratio of two measures: the 
first computes the average distance of the data point to its K nearest 
neighbors; the second computes the average of the pairwise distances of the 
neighbors themselves. Again, the higher the value the more the data point is an 
outlier.

As you can see, these four algorithms work differently, so they don't always 
agree on which points are outliers. By default, we use all these methods during 
{oldetection}, then normalize and combine their results and give every datapoint 
in the index an {olscore}. The {olscore} ranges from 0 to 1, where the higher 
number represents the chance that the data point is an outlier compared to the 
other data points in the index.

IMPORTANT: {oldetection-cap} is a batch analysis, it runs against your data 
once. If new data comes into the index, you need to do the analysis again on the 
altered data.

[discrete]
[[dfa-feature-influence]]
=== Feature influence

Besides the {olscore}, another value is calculated during {oldetection}: 
the feature influence score. As we mentioned, there are multiple features of a 
data point that are analyzed during {oldetection}. An influential feature is a 
feature of a data point that is responsible for the point being an outlier. The 
value of feature influence provides a relative ranking of features by their 
contribution to a point being an outlier. Therefore, while {olscore} tells us 
whether a data point is an outlier, feature influence shows which features make 
the point an outlier. By doing this, this value provides context to help 
understand more about the reasons for the data point being unusual and can drive 
visualizations.

//FIGURE ON FEATURE INFLUENCE

[discrete]
[[ml-outlier-detection-evaluate]]
=== {oldetection-cap} evaluation

include::ml-dfa-shared.asciidoc[tag=dfa-evaluation-intro]

The {oldetection} evaluation type is suitable for analyses which calculate a 
probability that each data point in a data set is a member of a class or not. It 
offers the following metrics to evaluate the model performance:

* confusion matrix
* precision
* recall
* receiver operating characteristic (ROC) curve.

[discrete]
[[ml-dfanalytics-confusion-matrix]]
==== Confusion matrix

A confusion matrix provides four measures of how well the {dfanalytics} worked 
on your data set:

* True positives (TP): Class members that the analysis identified as class 
members.
* True negatives (TN): Not class members that the analysis identified as not 
class members.
* False positives (FP): Not class members that the analysis misidentified as 
class members.
* False negatives (FN): Class members that the analysis misidentified as not 
class members.

Although, the {evaluatedf-api} can compute the confusion matrix out of the 
analysis results, these results are not binary values (class member/not 
class member), but a number between 0 and 1 (which called the {olscore} in case 
of {oldetection}). This value captures how likely it is for a data 
point to be a member of a certain class. It means that it is up to the user who 
is evaluating the results to decide what is the threshold or cutoff point at 
which the data point will be considered as a member of the given class. For 
example, in the case of {oldetection} the user can say that all the data points 
with an {olscore} higher than 0.5 will be considered as outliers.

To take this complexity into account, the {evaluatedf-api} returns the confusion 
matrix at different thresholds (by default, 0.25, 0.5, and 0.75).

[discrete]
[[ml-dfanalytics-precision-recall]]
==== Precision and recall

A confusion matrix is a useful measure, but it could be hard to compare the 
results across the different algorithms. Precision and recall values
summarize the algorithm performance as a single number that makes it easier to 
compare the evaluation results.

Precision shows how many of the data points that the algorithm identified as 
class members were actually class members. It is the number of true positives 
divided by the sum of the true positives and false positives (TP/(TP+FP)).

Recall answers a slightly different question. This value shows how many of the 
data points that are actual class members were identified correctly as class 
members. It is the number of true positives divided by the sum of the true 
positives and false negatives (TP/(TP+FN)).

As was the case for the confusion matrix, you also need to define different 
threshold levels for computing precision and recall.

[discrete]
[[ml-dfanalytics-roc]]
==== Receiver operating characteristic curve

The receiver operating characteristic (ROC) curve is a plot that represents the 
performance of the binary classification process at different thresholds. It 
compares the rate of true positives against the rate of false positives at the 
different threshold levels to create the curve. From this plot, you can compute 
the area under the curve (AUC) value, which is a number between 0 and 1. The 
closer to 1, the better the algorithm performance.

The {evaluatedf-api} can return the false positive rate (`fpr`) and the true 
positive rate (`tpr`) at the different threshold levels, so you can visualize 
the algorithm performance by using these values.


[discrete]
[[ecommerce-outliers]]
== Detecting unusual behavior in the eCommerce data set

The goal of <<dfa-outlier-detection,{oldetection}>> is to find the most unusual
documents in an index. Let's try to detect unusual customer behavior in the 
{kibana-ref}/add-sample-data.html[eCommerce sample data set]. 

. Verify that your environment is set up properly to use {ml-features}. 
If the {es} {security-features} are enabled, you need a user that has authority
to create and manage {dfanalytics-jobs}. See <<setup>>.
+
--
Since we'll be creating {transforms}, you also need
`manage_data_frame_transforms` cluster privileges.
--

. Create a {transform} that generates an entity-centric index with numeric or
boolean data to analyze.
+
--
In this example, we'll use the eCommerce orders sample data and pivot the data
such that we get a new index that contains a sales summary for each customer.

In particular, create a {transform} that calculates the sum of the products
(`products.quantity`) and the sum of prices (`products.taxful_price`) in all of
the orders, grouped by customer (`customer_full_name.keyword`). Also include a 
value count aggregation, so that we know how many orders (`order_id`) exist for 
each customer.

You can preview the {transform} before you create it in *{stack-manage-app}*
> *Transforms*:

[role="screenshot"]
image::images/ecommerce-transform-preview.png["Creating a {transform} in {kib}"]

Alternatively, you can use the
{ref}/preview-transform.html[preview {transform} API] and the
{ref}/put-transform.html[create {transform} API].

.API example
[%collapsible]
====
[source,console]
--------------------------------------------------
POST _data_frame/transforms/_preview
{
  "source": {
    "index": [
      "kibana_sample_data_ecommerce"
    ]
  },
  "pivot": {
    "group_by": {
      "customer_full_name.keyword": {
        "terms": {
          "field": "customer_full_name.keyword"
        }
      }
    },
    "aggregations": {
      "products.quantity.sum": {
        "sum": {
          "field": "products.quantity"
        }
      },
      "products.taxful_price.sum": {
        "sum": {
          "field": "products.taxful_price"
        }
      },
      "order_id.value_count": {
        "value_count": {
          "field": "order_id"
        }
      }
    }
  }
}

PUT _data_frame/transforms/ecommerce-customer-sales
{
  "source": {
    "index": [
      "kibana_sample_data_ecommerce"
    ]
  },
  "pivot": {
    "group_by": {
      "customer_full_name.keyword": {
        "terms": {
          "field": "customer_full_name.keyword"
        }
      }
    },
    "aggregations": {
      "products.quantity.sum": {
        "sum": {
          "field": "products.quantity"
        }
      },
      "products.taxful_price.sum": {
        "sum": {
          "field": "products.taxful_price"
        }
      },
      "order_id.value_count": {
        "value_count": {
          "field": "order_id"
        }
      }
    }
  },
  "description": "E-commerce sales by customer",
  "dest": {
    "index": "ecommerce-customer-sales"
  }
}
--------------------------------------------------
// TEST[skip:set up sample data]
====

For more details about creating {transforms}, see
{ref}/ecommerce-transforms.html[Transforming the eCommerce sample data].
--

. Start the {transform}.
+
--

TIP: Even though resource utilization is automatically adjusted based on the
cluster load, a {transform} increases search and indexing load on your
cluster while it runs. If you're experiencing an excessive load, however, you
can stop it.

You can start, stop, and manage {transforms} in {kib}. Alternatively, you can
use the {ref}/start-data-frame-transform.html[start {transforms}] API.

.API example
[%collapsible]
====
[source,console]
--------------------------------------------------
POST _data_frame/transforms/ecommerce-customer-sales/_start
--------------------------------------------------
// TEST[skip:setup kibana sample data]
====
--

. Create a {dfanalytics-job} to detect outliers in the new entity-centric index.
+
--
In the wizard on the *Machine Learning* > *Data Frame Analytics* page in {kib},
select your new index pattern then use the default values for {oldetection}. For
example:

[role="screenshot"]
image::images/ecommerce-outlier-job-1.png["Create a {dfanalytics-job} in {kib}"]

The wizard includes a scatterplot matrix, which enables you to explore the 
relationships between the fields. You can use that information to help you
decide which fields to include or exclude from the analysis.

[role="screenshot"]
image::images/ecommerce-outlier-scatterplot.png["A scatterplot matrix for three fields in {kib}"]

If you want these charts to represent data from a larger sample size or from a
randomized selection of documents, you can change the default behavior. However, 
a larger sample size might slow down the performance of the matrix and a
randomized selection might put more load on the cluster due to the more
intensive query.

Alternatively, you can use the
{ref}/put-dfanalytics.html[create {dfanalytics-jobs} API].

.API example
[%collapsible]
====
[source,console]
--------------------------------------------------
PUT _ml/data_frame/analytics/ecommerce
{
  "source": {
    "index": "ecommerce-customer-sales"
  },
  "dest": {
    "index": "ecommerce-outliers"
  },
  "analysis": {
    "outlier_detection": {
    }
  },
  "analyzed_fields" : {
    "includes" : ["products.quantity.sum","products.taxful_price.sum","order_id.value_count"]
  }
}
--------------------------------------------------
// TEST[skip:setup kibana sample data]
====
--

. Start the {dfanalytics-job}.
+
--
You can start, stop, and manage {dfanalytics-jobs} on the *Machine Learning* > 
*Data Frame Analytics* page. Alternatively, you can use the
{ref}/start-dfanalytics.html[start {dfanalytics-jobs}] and
{ref}/stop-dfanalytics.html[stop {dfanalytics-jobs}] APIs.

.API example
[%collapsible]
====
[source,console]
--------------------------------------------------
POST _ml/data_frame/analytics/ecommerce/_start
--------------------------------------------------
// TEST[skip:setup kibana sample data]
====
--

. View the results of the {oldetection} analysis.
+
--
The {dfanalytics-job} creates an index that contains the original data and
{olscores} for each document. The {olscore} indicates how different each entity
is from other entities.

In {kib}, you can view the results from the {dfanalytics-job} and sort them
on the outlier score:

[role="screenshot"]
image::images/outliers.png["View {oldetection} results in {kib}"]

The `ml.outlier` score is a value between 0 and 1. The larger the value, the
more likely they are to be an outlier. In {kib}, you can optionally enable
histogram charts to get a better understanding of the distribution of values for
each column in the result.

In addition to an overall outlier score, each document is annotated with feature
influence values for each field. These values add up to 1 and indicate which
fields are the most important in deciding whether an entity is an outlier or
inlier. For example, the dark shading on the `products.taxful_price.sum` field
for Wagdi Shaw indicates that the sum of the product prices was the most
influential feature in determining that Wagdi is an outlier.

If you want to see the exact feature influence values, you can retrieve them
from the index that is associated with your {dfanalytics-job}.

.API example
[%collapsible]
====
[source,console]
--------------------------------------------------
GET ecommerce-outliers/_search?q="Wagdi Shaw"
--------------------------------------------------
// TEST[skip:setup kibana sample data]

The search results include the following {oldetection} scores:

[source,js]
--------------------------------------------------
...
  "ml" : {
    "outlier_score" : 0.9706582427024841,
    "feature_influence" : [
      {
        "feature_name" : "order_id.value_count",
        "influence" : 0.015179949812591076
      },
      {
        "feature_name" : "products.quantity.sum",
        "influence" : 0.003752298653125763
      },
      {
        "feature_name" : "products.taxful_price.sum",
        "influence" : 0.9810677766799927
      }
    ]
  }
...
--------------------------------------------------
// NOTCONSOLE
====

{kib} also provides a scatterplot matrix in the results. Outliers with a score 
that exceeds the threshold are highlighted in each chart:

[role="screenshot"]
image::images/outliers-scatterplot.png["View scatterplot in {oldetection} results"]

In addition to the sample size and random scoring options, there is a
*Dynamic size* option. If you enable this option, the size of each point is 
affected by its {olscore}; that is to say, the largest points have the
highest {olscores}. The goal of these charts and options is to help you 
visualize and explore the outliers within your data.

--

Now that you've found unusual behavior in the sample data set, consider how you
might apply these steps to other data sets. If you have data that is already
marked up with true outliers, you can determine how well the {oldetection}
algorithms perform by using the evaluate {dfanalytics} API. See
<<ml-outlier-detection-evaluate>>.

TIP: If you do not want to keep the {transform} and the {dfanalytics-job}, you
can delete them in {kib} or use the
{ref}/delete-data-frame-transform.html[delete {transform} API] and
{ref}/delete-dfanalytics.html[delete {dfanalytics-job} API]. When you delete
{transforms} and {dfanalytics-jobs} in {kib}, you have the option to also remove
the destination indices and index patterns.


[discrete]
[[outlier-detection-next]]
=== What's next

* If you want to see another example of {oldetection} in a Jupyter notebook,
https://github.com/elastic/examples/tree/master/Machine%20Learning/Outlier%20Detection/Introduction[click here].

* https://www.elastic.co/blog/catching-malware-with-elastic-outlier-detection[This blog post]
shows you how to catch malware using {oldetection}.
