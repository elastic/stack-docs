[role="xpack"]
[[ml-buckets]]
=== Buckets
++++
<titleabbrev>Buckets</titleabbrev>
++++

The {ml-features} use the concept of a _bucket_ to divide the time series into
batches for processing.

The _bucket span_ is part of the configuration information for an {anomaly-job}.
It defines the time interval that is used to summarize and model the data. This
is typically between 5 minutes to 1 hour and it depends on your data
characteristics. When you set the bucket span, take into account the granularity
at which you want to analyze, the frequency of the input data, the typical
duration of the anomalies, and the frequency at which alerting is required.

////
The bucket span has two purposes: it dictates over what time span to look for anomalous features in data, and also determines how quickly anomalies can be detected. Choosing a shorter bucket span enables anomalies to be detected more quickly. However, there is a risk of being too sensitive to natural variations or noise in the input data. Choosing too long a bucket span can mean that interesting anomalies are averaged away. There is also the possibility that the aggregation might smooth out some anomalies based on when the bucket starts in time.

The bucket span has a significant impact on the analysis. When youâ€™re trying to determine what value to use, take into account the granularity at which you want to perform the analysis, the frequency of the input data, the duration of typical anomalies, and the frequency at which alerting is required.
////

[discrete]
[[ml-bucket-results]]
==== Bucket results

When you view your {ml} results, each bucket has an anomaly score. This score is
a statistically aggregated and normalized view of the combined anomalousness of
all the record results in the bucket.

The {ml} analytics enhance the anomaly score for each bucket by considering
contiguous buckets. This extra _multi-bucket analysis_ effectively uses a
sliding window to evaluate the events in each bucket relative to the larger
context of recent events. When you review your {ml} results, there is a 
`multi_bucket_impact` property that indicates how strongly the final anomaly
score is influenced by multi-bucket analysis. In {kib}, anomalies with medium or
high multi-bucket impact are depicted in the *Anomaly Explorer* and the
*Single Metric Viewer* with a cross symbol instead of a dot. For example:

[role="screenshot"]
image::images/multibucketanalysis.jpg["Examples of anomalies with multi-bucket impact in {kib}"]

In this example, you can see that some of the anomalies fall within the shaded
blue area, which represents the bounds for the expected values. The bounds are
calculated per bucket, but multi-bucket analysis is not limited by that scope.

If you have more than one {anomaly-job}, you can also obtain _overall bucket_
results, which combine and correlate anomalies from multiple jobs into an
overall score. When you view the results for job groups in {kib}, it provides
the overall bucket scores. For more information, see
{ref}/ml-get-overall-buckets.html[Get overall buckets API].

Bucket results provide the top level, overall view of the {anomaly-job} and are
ideal for alerts. For example, the bucket results might indicate that at 16:05
the system was unusual. This information is a summary of all the anomalies,
pinpointing when they occurred. When you identify an anomalous bucket, you can
investigate further by examining the pertinent records.