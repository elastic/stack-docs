[[ml-nlp-e5]]
= E5 – EmbEddings from bidirEctional Encoder rEpresentations
++++
<titleabbrev>E5</titleabbrev>
++++

:frontmatter-description: E5 is a multilingual dense vector model.
:frontmatter-tags-products: [ml] 
:frontmatter-tags-content-type: [how-to] 
:frontmatter-tags-user-goals: [analyze]

experimental[]

EmbEddings from bidirEctional Encoder rEpresentations - or E5 -  is a {nlp} 
model that enables you to perform multi-lingual semantic search by using dense 
vector representations. This model performs best for non-English language 
documents and queries. If you want to perform semantic search on English 
language documents, use the <<ml-nlp-elser>> model.

{ref}/semantic-search.html[Semantic search] provides you search results based on 
contextual meaning and user intent, rather than exact keyword matches.

E5 has two versions: one cross-platform version which runs on any hardware 
and one version which is optimized for Intel® silicon. The 
**Model Management** > **Trained Models** page shows you which version of E5 is 
recommended to deploy based on your cluster's hardware.

The supported model version of E5 is `multilingual-e5-small`, refer to 
<<ml-nlp-e5-limit, this page>> for more information.


[discrete]
[[e5-req]]
== Requirements

To use E5, you must have the {subscriptions}[appropriate subscription] level 
for semantic search or the trial period activated.


[discrete]
[[download-deploy-e5]]
== Download and deploy E5

You can download and deploy the E5 model either from 
**{ml-app}** > **Trained Models**, from **Search** > **Indices**, or by using 
the Dev Console.


[discrete]
[[trained-model-e5]]
=== Using the Trained Models page

1. In {kib}, navigate to **{ml-app}** > **Trained Models**. E5 can be found in 
the list of trained models. There are two versions available: one portable 
version which runs on any hardware and one version which is optimized for Intel® 
silicon. You can see which model is recommended to use based on your hardware 
configuration.
2. Click the **Add trained model** button. Select the E5 model version you want 
to use in the opening modal window. The model that is recommended for you based 
on your hardware configuration is highlighted. Click **Download**. You can check 
the download status on the **Notifications** page.
+
--
[role="screenshot"]
image::images/ml-nlp-e5-download.png[alt="Downloading E5",align="center"]
--
+
--
Alternatively, click the **Download model** button under **Actions** in the 
trained model list.
--
3. After the download is finished, start the deployment by clicking the 
**Start deployment** button.
4. Provide a deployment ID, select the priority, and set the number of 
allocations and threads per allocation values.
// TO DO: Add screenshot.
5. Click Start.


[discrete]
[[elasticsearch-e5]]
=== Using the search indices UI

Alternatively, you can download and deploy the E5 model to an {infer} pipeline 
using the search indices UI.

1. In {kib}, navigate to **Search** > **Indices**.
2. Select the index from the list that has an {infer} pipeline in which you want 
to use E5.
3. Navigate to the **Pipelines** tab.
4. Under **{ml-app} {infer-cap} Pipelines**, click the **Deploy** button to 
begin downloading the E5 model. This may take a few minutes depending on your 
network. 
// TO DO: Add screenshot.
5. Once the model is downloaded, click the **Start single-threaded** button to 
start the model with basic configuration or select the **Fine-tune performance** 
option to navigate to the **Trained Models** page where you can configure the 
model deployment.
// TO DO: Add screenshot.

When your E5 model is deployed and started, it is ready to be used in a 
pipeline.


[discrete]
[[dev-console-e5]]
=== Using the Dev Console

1. In {kib}, navigate to the **Dev Console**.
2. Create the E5 model configuration by running the following API call:
+
--
[source,console]
----------------------------------
PUT _ml/trained_models/.multilingual-e5-small
{
  "input": {
	"field_names": ["text_field"]
  }
}
----------------------------------

The API call automatically initiates the model download if the model is not 
downloaded yet.
--
3. Deploy the model by using the 
{ref}/start-trained-model-deployment.html[start trained model deployment API] 
with a delpoyment ID:
+
--
[source,console]
----------------------------------
POST _ml/trained_models/.multilingual-e5-small/deployment/_start?deployment_id=for_search
----------------------------------
--