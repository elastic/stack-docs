tag::feature-importance[]
Feature importance is calculated for supervised {ml} methods such as 
{regression} and {classification}. This value provides further insight into the 
results of a {dfanalytics-job} and therefore helps interpret these results. As we 
mentioned, there are multiple features of a data point that are analyzed during 
{dfanalytics}. These features are responsible for a particular prediction to 
varying degrees. Feature importance shows to what degree a given feature of a 
data point contributes to the prediction. The feature importance value of a 
feature can be either positive or negative depending on its effect on the 
prediction. If the feature reduces the prediction value, the value is negative. 
If the feature increases the prediction, the feature importance value positive.
The magnitude of the feature importance value shows how significantly the
feature affects the prediction both locally (for a given data point) or
generally (for the whole data set).

Feature importance in the {stack} is calculated using the SHAP (SHapley Additive 
exPlanations) method as described in
https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf[Lundberg, S. M., & Lee, S.-I. A Unified Approach to Interpreting Model Predictions. In NeurIPS 2017.].
end::feature-importance[]