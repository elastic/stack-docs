[[install-logs-monitoring]]
[role="xpack"]
== Install Logs

The easiest way to get started with Elastic Logs is by using our hosted {es} Service on Elastic Cloud.
The {es} Service is available on both AWS and GCP, and automatically configures {es} and {kib}.

NOTE: If your data uses nonstandard fields, you may need to modify some of the default <<configure-logs-source,configuration settings>>.

[float]
=== Hosted Elasticsearch Service

Skip installing and managing your own {es} and {kib} instance by using our hosted {es} Service.
{ess-trial}[Try out the {es} Service for free].

[float]
=== Install the stack yourself

If you'd rather install the stack yourself,
first see the https://www.elastic.co/support/matrix[Elastic Support Matrix] for information about supported operating systems and product compatibility.

* <<install-elasticsearch-logs>>
* <<install-kibana-logs>> (version 6.5 or later) with a basic license
* <<install-shippers>> (version 6.5 or later) on each of the systems you want to
monitor

[[install-elasticsearch-logs]]
=== Step 1: Install Elasticsearch

Install an {es} cluster, start it up, and make sure it's running.

. Verify that your system meets the
https://www.elastic.co/support/matrix#matrix_jvm[minimum JVM requirements] for {es}.
. {stack-gs}/get-started-elastic-stack.html#install-elasticsearch[Install Elasticsearch].
. {stack-gs}/get-started-elastic-stack.html#_make_sure_elasticsearch_is_up_and_running[Make sure elasticsearch is up and running].

[[install-kibana-logs]]
=== Step 2: Install Kibana

Install {kib}, start it up, and open up the web interface:

. {stack-gs}/get-started-elastic-stack.html#install-kibana[Install Kibana].
. {stack-gs}/get-started-elastic-stack.html#_launch_the_kibana_web_interface[Launch the Kibana Web Interface].

[[install-shippers]]
=== Step 3: Set up and run {filebeat}

IMPORTANT: This section describes using {filebeat} to ingest data. There are other available methods to ingest data, such as {logstash-ref}/introduction.html[{ls}] or Fluentd.

To start collecting logs data, you need to install {filebeat} and configure the {filebeat} modules directly from Kibana.

Alternatively, you can install {filebeat} and configure the {filebeat} modules yourself.

[float]
==== Install {filebeat} from {kib}

IMPORTANT: {filebeat-ref}/filebeat-modules.html[{filebeat} modules]
are ECS-compliant so manual <<logs-ecs-fields, ECS field>> mapping is not required, and all {logs-app}
data is automatically populated. 

To install a {filebeat} module from {kib}, on the machine where you want to collect the data, open a {kib} browser window.
In the *Observability* section displayed on the home page of {kib}, click *Add log data*.
Now follow the instructions for the type of data you want to collect.
The instructions include how to install and configure {filebeat}, and enable the appropriate {filebeat} module for your data.

[role="screenshot"]
image::images/add-data.png[Add log data]

[float]
==== Install {filebeat} yourself

If your data source doesn't have a {filebeat} module, or if you want to install one the old fashioned way, follow the instructions in {filebeat-ref}/filebeat-modules-quickstart.html[{filebeat} modules quick start] and enable modules for the logs you want to collect.
If there is no module for the logs you want to collect, see the {filebeat-ref}/filebeat-getting-started.html[{filebeat} getting started] to learn how to configure inputs.

[float]
=== Enable {filebeat} modules

To start collecting logs data, you need to enable the appropriate modules in {filebeat}.

To collect logs from your host system, enable:

* {filebeat-ref}/filebeat-module-system.html[{filebeat} `system` module]
* {filebeat-ref}/filebeat-modules.html[Other {filebeat} modules] needed for your environment, such as `apache2`, `redis`, and so on

To collect logs from Docker containers, enable:

* {filebeat-ref}/filebeat-input-docker.html[{filebeat} `docker` input]
* {filebeat-ref}/add-docker-metadata.html[{filebeat} `add_docker_metadata` processor]

To collect logs from Kubernetes pods, enable:

* {filebeat-ref}/filebeat-input-docker.html[{filebeat} `docker` input]
* {filebeat-ref}/add-kubernetes-metadata.html[{filebeat} `add_kubernetes_metadata` processor]

[float]
=== Configure your data sources

If your logs data has nonstandard fields, you may need to modify some configuration settings in {kib}, such as the index pattern used to query the data, and the timestamp field used for sorting.
To modify configuration settings, use the <<configure-logs-source,Settings tab>> in the {logs-app}.
Alternatively, see {kibana-ref}/logs-ui-settings-kb.html[{logs} settings] for a complete list of logs configuration settings.

[float]
=== More about container monitoring

If you're monitoring Docker containers or Kubernetes pods, you can use autodiscovery to automatically change the configuration settings in response to changes in your containers.
Autodiscovery ensures that even when your container configuration changes, data is still collected.
To learn how to do this, see {filebeat-ref}/configuration-autodiscover.html[{filebeat} autodiscover configuration].
