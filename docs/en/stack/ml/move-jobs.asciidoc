[chapter,role="xpack"]
[[move-jobs]]
= Export and import {ml} jobs
++++
<titleabbrev>Exporting and importing {ml} jobs</titleabbrev>
++++
:keywords: {ml-init}, {stack}, {anomaly-detect}, {dfanalytics}

You can export and import your {ml} job and {dfeed} configuration details in the
*{stack-manage-app}* app in {kib}. For example, you can export jobs from your
test environment and import them into your production environment.

The exported file contains configuration details; it does not contain the {ml}
models. For {anomaly-detect}, you must import and run the job to build a model
that is accurate for the new environment. For {dfanalytics}, trained models are
portable and can be transferred between clusters as described in
<<export-import>>.

When you export {anomaly-jobs}, filter lists are not included. If your job uses 
<<ml-configuring-detector-custom-rules,custom rules>> with filter lists, you
must create the filter list before you import the job; otherwise, the import
fails. You can create filter lists in {kib} or with the
{ref}/ml-put-filter.html[create filters API].

Likewise, when you export {anomaly-jobs}, <<ml-calendars,calendars>> are not
included. If you want to continue to use calendars in the new environment, you
can use {kib} to create them and assign your imported jobs. Alternatively, use
the {ref}/ml-put-calendar.html[create calendars],
{ref}/ml-post-calendar-event.html[add events to calendar], and
{ref}/ml-put-calendar-job.html[add jobs to calendar] APIs.
