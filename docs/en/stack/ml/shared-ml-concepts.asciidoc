tag::feature-importance[]
Feature importance is calculated for supervised {ml} methods such as 
{regression} and {classification}. This value provides further insight into the 
results of a {dfanalytics-job} and therefore helps interpret these results. As we 
mentioned, there are multiple features of a data point that are analyzed during 
{dfanalytics}. These features are responsible for a particular prediction to 
varying degrees. Feature importance shows to what degree a given feature of a 
data point contributes to the prediction. The feature importance value of a 
feature can be either positive or negative depending on its effect on the 
prediction. If the feature reduces the prediction value, the value is negative. 
If the feature increases the prediction, the feature importance value positive.
The magnitude of the feature importance value shows how significantly the
feature affects the prediction both locally (for a given data point) or
generally (for the whole data set).

Feature importance in the {stack} is calculated using the SHAP (SHapley Additive 
exPlanations) method as described in
https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf[Lundberg, S. M., & Lee, S.-I. A Unified Approach to Interpreting Model Predictions. In NeurIPS 2017].

By default, feature importance values are not calculated. To generate this
information, when you create a {dfanalytics-job} you must specify the 
`num_top_feature_importance_values` property. The feature importance values are
stored in the destination index in fields prefixed by `ml.feature_importance`.

NOTE: The number of feature importance values for each document might be less
than the `num_top_feature_importance_values` property value. For example, it
returns only features that had a positive or negative effect on the prediction.

end::feature-importance[]
