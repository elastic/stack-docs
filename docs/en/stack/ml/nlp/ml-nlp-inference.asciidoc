[[ml-nlp-inference]]
= Add NLP to pipelines
:keywords: {ml-init}, {stack}, {nlp}, inference 

coming::[8.0.0]

After you <<ml-nlp-deploy-models,deploy a trained model in your cluster>>, you
can use it to perform {nlp} tasks at ingest time.

[discrete]
[[ml-nlp-pipelines]]
== Inference processors

You can use trained models to perform {nlp} tasks in your
{ref}/ingest.html[ingest pipeline]. In particular, you can reference a trained
model in an {ref}/inference-processor.html[inference processor].

//TO-DO: Add example
//TBD: Add nlp options to inference processor's inference_config reference?
