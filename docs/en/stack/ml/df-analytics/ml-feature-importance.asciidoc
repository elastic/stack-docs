[role="xpack"]
[[ml-feature-importance]]
= {feat-imp-cap}

{feat-imp-cap} values indicate which fields had the biggest impact on each 
prediction that is generated by <<dfa-classification,{classification}>> or 
<<dfa-regression,{regression}>> analysis. The features of the data points are 
responsible for a particular prediction to varying degrees. {feat-imp-cap} shows 
to what degree a given feature of a data point contributes to the prediction. 
The {feat-imp} value can be either positive or negative depending on its effect 
on the prediction. If the feature reduces the prediction value, the {feat-imp} 
is negative, if it increases the prediction, then the {feat-imp} is positive. 
The magnitude of {feat-imp} shows how significantly the feature affects the 
prediction both locally (for a given data point) or generally (for the whole 
data set).

{feat-imp-cap} in the {stack} is calculated using the SHAP (SHapley Additive 
exPlanations) method as described in
https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf[Lundberg, S. M., & Lee, S.-I. A Unified Approach to Interpreting Model Predictions. In NeurIPS 2017].

By default, {feat-imp} values are not calculated when you configure the job via 
the API. To generate this information, when you create a {dfanalytics-job} you 
must specify the `num_top_feature_importance_values` property. When you 
configure the job in {kib}, {feat-imp} values are calculated automatically. The 
{feat-imp} values are stored in the {ml} results field for each document in the 
destination index.

NOTE: The number of {feat-imp} values for each document might be less than the 
`num_top_feature_importance_values` property value. For example, it returns only 
features that had a positive or negative effect on the prediction.

[[ml-feature-importance-readings]]
== Further reading

https://www.elastic.co/blog/feature-importance-for-data-frame-analytics-with-elastic-machine-learning[{feat-imp-cap} for {dfanalytics} with Elastic {ml}]
