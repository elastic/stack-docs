[role="xpack"]
[[dfa-regression]]
== {regression-cap}

{reganalysis-cap} is a {ml} process for estimating the relationships among 
a number of {feature-vars} and a {depvar}, then making further predictions based 
on these relationships.

For example, suppose we are interested in finding the relationship between 
apartment size and monthly rent in a city. In this example, the rent is the 
{depvar} while the apartment size is the {feature-var} and we try to find out 
the relationship between them in order to make further predictions. Our 
imaginary dataset consists of three data points:

|===
| Size (m2) | Monthly rent 
| 44        | 1600
| 24        | 1055
| 63        | 2300
|===

After the model determines the relationship between the {feature-vars} (apartment size) and the 
{depvar} (rent), it can make predictions such as the monthly rent of a hundred square meter-size 
apartment.

This is a simple example. Usually {regression} problems are multi-dimensional, 
so the relationships that {reganalysis} tries to find are between multiple 
{feature-vars} and the {depvar}. To extend our example, a more complex 
{reganalysis} could take into account further {feature-vars} like the location 
of the apartment in the city, on which floor it is, and whether the apartment 
has a riverside view or not and so on.


[discrete]
[[dfa-regression-features]]
=== {feature-vars-cap}

{feature-vars-cap} are the values that the {depvar} value depends on. If one or 
more of the {feature-vars} changes, the {depvar} value also changes. There are 
three different types of {feature-vars} that you can use with our {regression} 
algorithm:

* Numerical. In our example, the size of the apartment was a 
  numerical {feature-var}.
* Categorical. A variable that can have one value from a set of values. The 
  value set has a fixed and limited number of possible items. In the example, 
  the location of the apartment in the city (borough) is a categorical variable.
* Boolean. The riverside view in the example is a boolean value because an 
  apartment either has a riverside view or doesn't have one.
Arrays are not supported.


[discrete]
[[dfa-regression-supervised]]
=== Training the {regression} algorithm

{regression-cap} is a supervised machine learning process, which means that you 
need to supply a labeled training dataset that has some {feature-vars} and a 
{depvar}. The {regression} algorithm learns the relationships between the 
features and the {depvar}. Once you've trained the model on your training 
dataset, you can reuse the knowledge that the model has learned about the 
relationships between the data points to make certain inferences about new data 
points.

The relationships between the {feature-vars} and the {depvar} is described as a 
mathematical formula. {reganalysis-cap} tries to find the best value for the 
{depvar} by combining various {ml} techniques, that means that in the {stack}, 
we use an ensemble learning model that uses multiple algorithms. The performance 
of an ensemble is usually better than the performance of an individual 
algorithm because each of the algorithms has a different bias, so each of them 
falls into different traps. When they are used together as a group, then they 
capture the characteristics of the data better. The ensemble learning technique 
that we use in the {stack} is a type of boosting called extreme gradient boost 
(XGboost) which combines decision trees with gradient boosting methodologies.

 
[discrete]
[[dfa-regression-evaluation]]
=== Measuring model performance

You can measure how well the model has performed on your training dataset by 
using the `regression` evaluation type of the {ref}/evaluate-dfanalytics.html[evaluate {dfanalytics} API]. The 
mean squared error value that the evaluation may provide you on the training 
dataset is the _training error_. Training the {regression} model means finding 
the combination of model parameters that produces the lowest possible training 
error.

Another crucial measurement is how well your model performs on unseen 
data points. To assess 
how well the trained model will perform on data it has never seen before, you must set aside a 
proportion of the training dataset needs to be set out for testing. This split 
of the dataset is the testing dataset. Once the model has been trained and found 
out the required coefficients, you can let the model predict the value of the 
data points it has never seen before and compare the prediction to the actual 
value. This test provides an estimate of a quantity known as the _model 
generalization error_.

Two concepts describe how well the {regression} algorithm was able to learn the 
relationship between the {feature-vars} and the {depvar}. Underfitting is when 
the model cannot capture the complexity of the dataset. Overfitting is when the 
model has trained through a dataset so sharply that it is capturing all the 
details and cannot generalize well enough. A model that overfits the data has a 
low mean squared error (MSE) value on the training dataset, but a high MSE value 
on the testing dataset. For more information about the evaluation metrics, see 
<<ml-dfanalytics-regression-evaluation>>.
