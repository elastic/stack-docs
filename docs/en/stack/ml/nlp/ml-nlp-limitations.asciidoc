[[ml-nlp-limitations]]
= Limitations

:frontmatter-description: List of limitations of the Elastic NLP features.
:frontmatter-tags-products: [ml] 
:frontmatter-tags-content-type: [troubleshooting] 
:frontmatter-tags-user-goals: [analyze]

The following limitations and known problems apply to the {version} release of 
the Elastic {nlp} trained models feature.

[discrete]
[[ml-nlp-large-documents-limit-10k-10mb]]
== Semantic text fields are limited at 10k chunks, limiting ingested document size to under ~10MB

When using semantic text to ingest documents chunking takes place automatically. The number
of chunks is limited by the cluster setting (index.mapping.nested_objects.limit)[https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-settings-limit.html]
which defaults to 10k. This means that documents which are too large will cause errors during 
ingestion. To avoid this issue, please split your documents into roughly 1MB parts before ingestion.

[discrete]
[[ml-nlp-elser-v1-limit-512]]
== ELSER semantic search is limited to 512 tokens per field that inference is applied to

When you use ELSER for semantic search, only the first 512 extracted tokens from 
each field of the ingested documents that ELSER is applied to are taken into 
account for the search process. If your data set contains long documents, divide 
them into smaller segments before ingestion if you need the full text to be 
searchable.
